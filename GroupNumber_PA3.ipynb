{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to AI (CS331): Project 3\n",
    "#### Name:\n",
    "#### Roll Number:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to import any other libraries that you might need in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1 [Decision Trees]\n",
    "### [35 marks]\n",
    "In this part, you have to implement the ID3 algorithm that you studied in class on a simple dataset.\n",
    "## Dataset\n",
    "You are provided with `car.txt`. It is a simple text file where each line represents a row of data. The details of what each feature represents is provided in the manual. Using this dataset, perform the following actions:\n",
    "1. The dataset has 4 class values: \n",
    "- unacc\n",
    "- acc\n",
    "- good\n",
    "- very good\n",
    "\n",
    "For simplifying the implementation of ID3 algorithm, we are going to change this to make only two classes: unacc and good. \n",
    "All the instances where class is unacc will remain unacc, but all the instances where the class is anything other than unacc (acc, good, or vey good), all of these would be changed to \"good\" and come under the same class.\n",
    "\n",
    "2. The dataset at the moment is quite large with more than 1700 rows and has a class imbalance as well. Reduce this to get a training dataset of 500 instances and a test dataset of 100 instances, both with roughly equal instances of both class values. \n",
    "3. Lastly, we will change the categorical variables to numbers to make it easier to work with. The conversion is given in the manual. However, do store the conversion somehwere as you are going to need to convert it back at the end to show the descision tree.\n",
    "4. As for how to show the decision tree, that is upto your descretion. The simplest way would be to represent it as dictionary of dictionaries, similar to the example given in the manual.\n",
    "5. Finally, evaluate your decision tree accuracy by running it for the test dataset and reporting the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 [Classification using DNN libraries]\n",
    "### [15 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you will be working with image data to type of image using sklearns MLP classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Make the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The images are present in a directory with the following structure: \n",
    "\n",
    "```\n",
    "Dataset\n",
    "│    \n",
    "└───train_data\n",
    "│   │...\n",
    "│   └───subfolders\n",
    "│       │   image1.jpg\n",
    "│       │   image2.jpg\n",
    "│       │   ...\n",
    "│   \n",
    "└───test_data\n",
    "    │...\n",
    "    └───subfolders\n",
    "        │   image1.jpg\n",
    "        │   image2.jpg\n",
    "        │   ...\n",
    "\n",
    "```\n",
    "Your task is to read the images from path, and store them in a numpy array to make your train and test set. A skeleton code has been provided to resize and read image from path. Sample pre-processing steps have been provided, feel free to play with it, remove or alter it as you see fit.\n",
    "\n",
    "\n",
    "Code provided is for notebook being run in windows environement, make necessary changes in path for colab, linux and macos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = []\n",
    "labels_train =[]\n",
    "folder_path = ...\n",
    "for  img in glob(folder_path+\"\\\\**\\\\*.jpg\"):\n",
    "    name = img.split('\\\\')\n",
    "    img_data = cv2.imread(img)\n",
    "    img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2GRAY)\n",
    "    img_data = cv2.resize(img_data, (20,20), interpolation= cv2.INTER_LINEAR)\n",
    "    \n",
    "folder_path = ...\n",
    "images_test = []\n",
    "labels_test =[]\n",
    "for  img in glob(folder_path+\"\\\\**\\\\*.jpg\"):\n",
    "    img_data = cv2.imread(img)\n",
    "    img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2GRAY)\n",
    "    img_data = cv2.resize(img_data, (20,20), interpolation= cv2.INTER_LINEAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the labels to integer encoding. Sklearns label encoder might help you with this. But you may use any other technique including one hot vectors if you wish\n",
    "\n",
    "Hint: Making a pandas dataframe out of the labels might be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the Neural Network\n",
    "\n",
    "You will be using Sklearns MLPClassifier for this task. Please dont use Tensorflow, pytorch or any other liabrary or a CNN based model etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters initialization\n",
    "\n",
    "max_iteration = ...\n",
    "learning_rate = ...\n",
    "hidden_layers = ...   # tuple in the form (n-t,...,n-2,n-1,n,)  dont forget the last ','\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier and make sure to use 20% data as validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "# Code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the accuracy and the f1 score on the test data set\n",
    "\n",
    "You may use Sklearns built in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the confusion matrix \n",
    "\n",
    "Use sklearns built in function and seaborn for visualization, make sure to annonate the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Part\n",
    "### [10 marks]\n",
    "\n",
    "### Maximize the accuracy to network parameter ratio and display it. This will be marked relatively\n",
    "\n",
    "you may use get_params() or dirrectly use your hidden layer tuple to calculate parameters\n",
    "\n",
    "To achieve marks your accuracy needs to be atleast 55%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3 [Neural Network from scratch]\n",
    "### [50 marks]\n",
    "Please go through the manual for details on this part. You are to use the `part3.csv` to train a model which you are going to make WITHOUT USING LIBRARIES. As you will see, since the data is completely seperable, your model should be able to get 100% accuracy, or something very close to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file here into your preferred data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visualise the dataset using a SINGLE scatter plot.\n",
    "Make sure to include:\n",
    "1. Different coloured points for each class\n",
    "2. A legend\n",
    "3. x and y labels\n",
    "4. PLot title\n",
    "'''\n",
    "\n",
    "# code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GETTING THE TEST AND TRAIN DATASETS [you are allowed to use a library for this]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK FROM SCRATCH AND TRAINING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING AND ACCURACY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And that's it! You're done with the programming part of this course :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
